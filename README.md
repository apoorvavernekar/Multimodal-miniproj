# Multimodal-miniproj
Human-computer interaction (HCI) has made a greater impact in today’s world. So considering a
user’s emotional status improves the human-computer interface. During communication, humans
exhibit a rich content of emotions through different modalities. Multimodal solutions are studied
alongside unimodal solutions as they provide more accuracy in terms of the classification of
emotions, thus it became necessary to develop a multimodal emotion recognition system. Since
literature provides greater importance to the facial expressions and several emotions like sadness,
fear can be easily distinguishable using the speech of a person, so here, these two modalities are
given more priority. This project uses these two modalities to find the emotional status of a person from
a video.
